{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b56a1b5-81c1-4c89-b1d7-61b964373fa8",
   "metadata": {},
   "source": [
    "![Logo UOC](https://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/logotips/logo-UOC-2linies.png)\n",
    "\n",
    "# TFG - Inteligencia Artificial\n",
    "Enero de 2026\n",
    "\n",
    "## Predicción de Respuesta a Tratamientos Oncológicos Basada en el Perfil Genético Mediante Técnicas de Aprendizaje Automático (ML) e Identificación de Genes Candidatos a Biomarcador Usando Técnicas de Explicabilidad (XAI) y Cuantificación de la Incertidumbre (UQ)\n",
    "\n",
    "---\n",
    "\n",
    "#### Pablo Vázquez Rodríguez\n",
    "##### Grado en Ingeniería Informática\n",
    "##### Inteligencia Artificial\n",
    "\n",
    "#### Dra. María Moreno de Castro\n",
    "#### Dr. Friman Sánchez\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a9cd0-f359-42f5-92fe-f6ca3a1b8ddc",
   "metadata": {},
   "source": [
    "## Modelado (Paso 1): Selección de características supervisada\n",
    "Como ya se comentó en el documento de exploración y preparación de datos durante el modelado se harán dos tareas:\n",
    "1. Selección de características supervisada\n",
    "2. Entrenamiento de modelos, comparaciones y selección del modelo óptimo\n",
    "\n",
    "Durante la primera tarea se realizará una selección de genes basada en modelos de regresión logística, Random Forest, XGBoost y CatBoost, modelados sobre el conjunto de datos reducido (el filtrado mediante varianza y análisis DEG).\n",
    "\n",
    "Durante la segunda tarea, y se entrenarán los modelos de nuevo esta vez sobre el conjunto que contiene sólo a los genes seleccionados. Tras el entrenamiento se evaluarán para elegir el modelo óptimo, sobre el que más adelante se aplicarán técnicas de explicabilidad y cuantificación de la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a920b-0acd-4a18-a1bb-6ae5eee12a85",
   "metadata": {},
   "source": [
    "## 0. Operaciones previas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52012133-73b6-4d4c-b79b-925d02519315",
   "metadata": {},
   "source": [
    "### Carga de módulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643ecc5-af36-4f4d-b57e-d68df0c0e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import get_scorer\n",
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505df0e-cb46-440d-8272-2d3eb87613df",
   "metadata": {},
   "source": [
    "### Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62300b86-3b72-4335-bfdd-87a408d1bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random generator de numpy con seed para reproducibilidad en el notebook\n",
    "rng_seed = 19293\n",
    "rng = np.random.default_rng(seed=rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba6248-412d-4349-a8ef-41a168e253bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los datasets\n",
    "df_full = pd.read_csv(\"./data/full_top_significance_dataset.csv\")\n",
    "df_train = pd.read_csv(\"./data/train_dataset.csv\")\n",
    "df_test = pd.read_csv(\"./data/test_dataset.csv\")\n",
    "df_cal = pd.read_csv(\"./data/calibration_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b5c34-3099-4f91-bc6a-0058b322aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES ÚTILES\n",
    "\n",
    "# Nombres de las columnas de genes\n",
    "gene_columns = df_full.columns.difference([\"Sample_id\", \"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd26e11-f605-4f69-918e-b5a01333e0f5",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea3865-a417-43be-a2e2-38a6467e2255",
   "metadata": {},
   "source": [
    "**train_with_cv**\n",
    "\n",
    "Como se usarán búsquedas de hiperparámetros, validación cruzada estratificada y siempre se usarán alguno de los siguientes algoritmos: Regresión Logística, Random Forest, XGBoost y CatBoost, se define una función auxiliar que permite:\n",
    "\n",
    "- Pasar un estimador de alguno de los algoritmos ya mencionados junto con la rejilla de parámetros a explorar\n",
    "- Configurar el número de splits de la validación cruzada\n",
    "- Definir el número de iteraciones del estudio de búsqueda de hiperparámetros\n",
    "- Detener las iteraciones internas cuando llega a 50 rondas sin mejorar la métrica objetivo (AUC). Sólo en XGBoost y CatBoost\n",
    "- Obtener un modelo entrenado con los mejores hiperparámetros encontrados\n",
    "\n",
    "Para la búsqueda de hiperparámetros se usa Optuna [https://optuna.org/] en lugar de los habituales GridSearchCV o RandomizedSearchCV. La razón es porque Optuna es mucho más eficiente, ya que optimiza la búsqueda de hiperparámetros teniendo en cuenta la información de iteraciones previas, tratando de maximizar la probabilidad de mejora de la métrica objetivo en cada iteración. (Ver: Tree-structured Parzen Estimator).\n",
    "\n",
    "Mientras que para GridSearchCV se le pasan valores concretos a explorar en el grid, a Optuna se le pasan rangos que el algoritmo explorará. Esto permite que el algoritmo se adapte a valores más optimizados y con menos riesgo de sesgos por elección arbitraria de estos. Gracias a eso, es mucho más eficiente a la hora de explorar espacios de hiperparámetros más grandes que de otro modo serían inabarcables o requerirían de mucho tiempo y capacidad de cómputo.\n",
    "\n",
    "Los algoritmos más pesados de los usados (XGBoost y CatBoost), en igualdad de condiciones con Optuna van mucho más rápido que los algoritmos ligeros (Regresión Logística y Random Forest). Esa ilusión es posible que se deba a que con XGBoost y CatBoost se usa early stopping, que además de mitigar problemas de sobreajuste hace que si el modelo, en iteraciones internas no mejora la métrica en 50 rondas, directamente pasa a la siguiente sin llegar a gastar todas las rondas que se hubiesen configurado para cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae77661-3c46-47b6-88e7-561494fd8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cv(estimator, param_grid, X_train, y_train,\n",
    "                  scoring=\"roc_auc\", n_splits=5, refit=True, n_jobs=-1, random=False, random_iters=20):\n",
    "    \"\"\"\n",
    "    Entrena un modelo con validación cruzada y búsqueda de hiperparámetros.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    original_estimator : sklearn estimator\n",
    "        Modelo base (LogisticRegression, RandomForestClassifier, XGBClassifier, CatBoost)\n",
    "    param_grid : dict\n",
    "        Diccionario con los hiperparámetros a explorar.\n",
    "    X_train : array-like\n",
    "        Matriz de entrenamiento.\n",
    "    y_train : array-like\n",
    "        Etiquetas de entrenamiento.\n",
    "    scoring : callable o str\n",
    "        Métrica de evaluación (por defecto AUCROC).\n",
    "    n_splits : int\n",
    "        Número de folds para StratifiedKFold.\n",
    "    n_trials: int\n",
    "        Número de trials para optimizar hiperparámetros\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    study_results : dict\n",
    "        Diccionario con: Objeto de estudio, mejores parámetros, mejor puntuación de métrica, \n",
    "        modelo entrenado con los mejores parámetros hallados\n",
    "    \"\"\"\n",
    "def train_with_cv(\n",
    "    original_estimator,\n",
    "    param_grid,\n",
    "    X_train, y_train,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_splits=5,\n",
    "    n_trials=30\n",
    "):\n",
    "    scorer = get_scorer(scoring)\n",
    "\n",
    "    def objective(trial):\n",
    "        # Construir kwargs del estimador a partir de la rejilla de parámetros\n",
    "        # En base al primer elemento del espacio:\n",
    "        #    \"I\": Espacio de enteros\n",
    "        #    \"F\": Espacio de floats\n",
    "        #    En cualquier otro caso: Espacio de categorías\n",
    "        params = {}\n",
    "        for name, space in param_grid.items():\n",
    "            match space[0]:\n",
    "                case \"I\":\n",
    "                    params[name] = trial.suggest_int(name, min(space[1:]), max(space[1:]))\n",
    "                case \"F\":\n",
    "                    params[name] = trial.suggest_float(name, min(space[1:]), max(space[1:]))\n",
    "                case _:\n",
    "                    params[name] = trial.suggest_categorical(name, space[1:])\n",
    "\n",
    "        # Clonar el estimador origen y actualizarlo con los hiperparámetros en cada iteración\n",
    "        model = clone(original_estimator)\n",
    "        model.set_params(**params, random_state=rng_seed)\n",
    "\n",
    "        # Crear los folds para la validación cruzada\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rng_seed)\n",
    "        scores = []\n",
    "\n",
    "        # Recorrer todos los folds de validación cruzada\n",
    "        #\n",
    "        # NOTA: Se tratan por separado los conjuntos de train y val de cada fold\n",
    "        # para poder aprovecharse de la evaluación con early_stopping que \n",
    "        # XGBoost y CatBoost permiten definir para ahorrar creaciones de árboles \n",
    "        # innecesarias si no hay mejoras\n",
    "        for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "            y_tr, y_val = y_train[train_idx], y_train[valid_idx]\n",
    "\n",
    "            # Ajuste con soporte de eval_set y early stopping\n",
    "            # Si los estimadores lo permiten, se usa early stopping\n",
    "            #\n",
    "            # NOTA: XGBClassifier da problemas si se le pasa el parámetro\n",
    "            #       early_stopping_rounds en el fit, así que hay que \n",
    "            #       tratarlo a parte\n",
    "            if isinstance(model, XGBClassifier):\n",
    "                model.set_params(early_stopping_rounds=50)\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            elif isinstance(model, CatBoostClassifier):\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=50, \n",
    "                          verbose=False)\n",
    "            else:\n",
    "                # Modelos que no soportan early stopping\n",
    "                model.fit(X_tr, y_tr)\n",
    "\n",
    "            # Se acumulan los scores de cada iteración para devolver la media al acabar todas las iteraciones sobre los kfolds\n",
    "            preds = model.predict_proba(X_val)[:, 1] if hasattr(model, \"predict_proba\") else model.predict(X_val)\n",
    "            scores.append(scorer._score_func(y_val, preds))\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Crear estudio y optimizar\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "\n",
    "    # Reentrenar con los mejores hiperparámetros y todos los datos de train\n",
    "    best_model = clone(original_estimator)\n",
    "    best_model = best_model.set_params(**best_params, random_state=rng_seed)\n",
    "\n",
    "    if isinstance(best_model, (XGBClassifier, CatBoostClassifier)):       \n",
    "        best_model.fit(X_train, y_train, verbose=False)\n",
    "    else:\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    study_results = {\n",
    "        \"study\": study,\n",
    "        \"best_params\": best_params,\n",
    "        \"best_score\": best_score,\n",
    "        \"best_model\": best_model\n",
    "    }\n",
    "    \n",
    "    return study_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a480572-1e30-4dc4-9147-960bd813ee18",
   "metadata": {},
   "source": [
    "### 1. Selección de características supervisada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf5bef-a381-4801-a78f-feb46fce5f4e",
   "metadata": {},
   "source": [
    "Como para la regresión logística se necesita trabajar con los datos escalados y teniendo en cuenta que a los algoritmos de árboles no les afecta si está o no escalado el dataset, usaremos el dataset escalado para todos los modelos.\n",
    "\n",
    "Además, como en este caso se quieren modelos sólo para valorar las características más importantes y estables entre ellos, vamos a explorar espacios relativamente grandes de hiperparámetros pero con relativamente pocas iteraciones de Optuna, ya que buscamos estabilidad de features y no tanto optimización de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf5758-234a-4ae5-8f15-177df7062b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de los datasets\n",
    "\n",
    "# Separar features y etiquetas\n",
    "X_train = df_train[gene_columns]\n",
    "y_train = df_train[\"Response\"]\n",
    "\n",
    "X_test = df_test[gene_columns]\n",
    "y_test = df_test[\"Response\"]\n",
    "\n",
    "X_cal = df_cal[gene_columns]\n",
    "y_cal = df_cal[\"Response\"]\n",
    "\n",
    "# Ajustar escalador con el dataset de train y aplicar a todos el mismo scaler\n",
    "scaler = StandardScaler().set_output(transform='pandas')\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transformar subconjuntos\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_cal_scaled = scaler.transform(X_cal)\n",
    "\n",
    "# Reconstruir dataframes escalados\n",
    "df_scaled_train = pd.concat([X_train_scaled, df_train[[\"Sample_id\", \"Response\"]]], axis=1)\n",
    "df_scaled_test = pd.concat([X_test_scaled, df_test[[\"Sample_id\", \"Response\"]]], axis=1)\n",
    "df_scaled_cal = pd.concat([X_cal_scaled, df_cal[[\"Sample_id\", \"Response\"]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b2de1-1f72-4c30-b580-f44ddb4ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503b9c2-2f26-44ec-b259-6e5f8b19fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos de entrenamiento para selección de genes\n",
    "X_train = df_scaled_train.drop(columns=[\"Response\", \"Sample_id\"])\n",
    "y_train = df_scaled_train[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd91b8-420f-441e-8c66-4ab9e951352b",
   "metadata": {},
   "source": [
    "**Regresión logística**:\n",
    "* La clase es de tipo categórico, pero scikit learn la transforma automáticamente en LogisticRegression.\n",
    "* Balanceada para paliar la asimetría del dataset\n",
    "* Uso de elasticnet como método de regularización para mitigar correlaciones y por la complejidad del dataset\n",
    "* Hiperparámetros:\n",
    "    * **solver=saga**: Es el único que soporta elasticnet\n",
    "    * **l1_ration**: Regularización Elasticnet: Balanceo de la regularización entre L1 y L2. Rango: \\[0-1\\]\n",
    "    * **C**: Inverso de la regularización: Fuerza de la regularización aplicada. Valores pequeños (ej. 0.1) implican regularización fuerte, valores grandes (ej. 10, 100) implican regularización débil.\n",
    "\n",
    "**NOTA**: La función auxiliar train_with_cv() incluye validación cruzada estratificada y un grid para ajustar la búsqueda de los mejores hiperparámetros.\n",
    "\n",
    "Se evalúan los espacios de hiperparámetros siguientes:\n",
    "* **C**: 0.01 a 10\n",
    "* **l1_ratio**: 0.1 a 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac94b5-04ca-4af4-88db-4b0dc2afec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Esta celda tarda alrededor de 15 minutos en el hardware original usado\n",
    "# Modelo de Regresión logística para selección de genes\n",
    "\n",
    "# Estimador\n",
    "log_reg = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", max_iter=5000, class_weight=\"balanced\")\n",
    "\n",
    "# Rangos de hiperparámetros\n",
    "log_reg_param_grid = {\"C\": [\"F\", 0.01, 10], \"l1_ratio\": [\"F\", 0.1, 0.9]}\n",
    "\n",
    "# Entrenamiento con validación cruzada\n",
    "log_reg_results = train_with_cv(log_reg, log_reg_param_grid, X_train, y_train,\n",
    "                  scoring=\"roc_auc\", n_splits=5)\n",
    "\n",
    "print(\"Mejores parámetros: \", log_reg_results[\"best_params\"], \"\\nMejor ROC_AUC=\", log_reg_results[\"best_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac949ceb-7772-49ed-81c7-f58ab6c58f7a",
   "metadata": {},
   "source": [
    "**Valores que se han obtenido**\n",
    "\n",
    "Checkpoint por si se vuelve a ejecutar y ya nos descuadra todo.\n",
    "Si eso sucediese, debería bastar con entrenar el modelo con los parámetros obtenido y que se muestran aquí abajo: \n",
    "\n",
    "**Mejores parámetros**:  {'C': 0.36028386220789177, 'l1_ratio': 0.8396386984992849}\n",
    "\n",
    "**Mejor ROC_AUC**= 0.6961021449215252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6bee5-13b2-4e7e-88f4-9833d013e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo de regresión logística\n",
    "best_logreg_model = log_reg_results[\"best_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cedd9d-5250-4517-8509-e38450f0dc81",
   "metadata": {},
   "source": [
    "**Random Forest**\n",
    "\n",
    "* Modelo basado en múltiples árboles de decisión entrenados sobre subconjuntos de datos y características.\n",
    "* Robusto frente a overfitting gracias al bagging.\n",
    "* Permite manejar datasets desbalanceados con class_weight=\"balanced\".\n",
    "* Para reproducibilidad random_state.\n",
    "* Hiperparámetros clave:\n",
    "    * **n_estimators**: Número de árboles. A más árboles más estabilidad pero más coste de procesado.\n",
    "    * **max_depth**: Profundidad máxima de cada árbol. Controla el sobreajuste\n",
    "    * **max_features**: Número de features consideradas en cada nodo. \n",
    "    * **min_samples_split**: Mínimo de muestras para dividir un nodo.\n",
    "\n",
    "Se evalúan todas las combinaciones de hiperparámetros siguientes:\n",
    "* **n_estimators**: 100 a 500\n",
    "* **max_depth**: 5 a 20\n",
    "* **max_features**: \"sqrt\" y \"log2\"\n",
    "* **min_samples_split**: 2 a 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fbb45b-2687-4e48-a05c-36efd301698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Esta celda tarda alrededor de 10 minutos en el hardware original usado\n",
    "# Modelo Random Forest para selección de genes\n",
    "\n",
    "# Estimador\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=rng_seed)\n",
    "\n",
    "# Rangos de hiperparámetros\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [\"I\", 100, 500],\n",
    "    \"max_depth\": [\"I\", 5, 20],\n",
    "    \"max_features\": [\"C\", \"sqrt\", \"log2\"],\n",
    "    \"min_samples_split\": [\"I\", 2, 10]\n",
    "}\n",
    "\n",
    "# Entrenamiento con validación cruzada\n",
    "rf_results = train_with_cv(rf, rf_param_grid, X_train, y_train, scoring=\"roc_auc\", n_splits=5)\n",
    "\n",
    "print(\"Mejores parámetros: \", rf_results[\"best_params\"], \n",
    "      \"\\nMejor ROC_AUC=\", rf_results[\"best_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acda452a-1b83-4b70-8002-053f40ae656b",
   "metadata": {},
   "source": [
    "**Valores que se han obtenido**\n",
    "\n",
    "Checkpoint por si se vuelve a ejecutar y ya nos descuadra todo.\n",
    "Si eso sucediese, debería bastar con entrenar el modelo con los parámetros obtenido y que se muestran aquí abajo: \n",
    "\n",
    "**Mejores parámetros**:  {'n_estimators': 354, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_split': 3} \n",
    "\n",
    "**Mejor ROC_AUC**= 0.7358667591318335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3e8c1-c672-4128-8b8d-5a925de87a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo de Random Forest\n",
    "best_rf_model = rf_results[\"best_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479b8e3-95b0-4c2e-a1e9-2daa6269a6d9",
   "metadata": {},
   "source": [
    "**XGBoost**\n",
    "\n",
    "* Algoritmo de boosting basado en gradiente, muy eficiente y potente.\n",
    "* Maneja correlaciones y complejidad del dataset mejor que Random Forest.\n",
    "* Permite ponderar clases desbalanceadas con scale_pos_weight.\n",
    "* No maneja variables categóricas automáticamente así que hay que codificarse con 0/1\n",
    "* Hiperparámetros clave:\n",
    "    * *De árbol*\n",
    "        * **n_estimators**: número de árboles.\n",
    "        * **max_depth**: profundidad máxima.\n",
    "        * **learning_rate**: tasa de aprendizaje.\n",
    "        * **min_child_weight**: Peso mínimo de un nodo para permitir la división (reduce sobreajuste)\n",
    "    * *De regularización*\n",
    "        * **reg_alpha**: Regularización L1\n",
    "        * **reg_lambda**: Regularización L2\n",
    "    * *De muestreo*\n",
    "        * **subsample**: fracción de muestras usadas en cada árbol.\n",
    "        * **colsample_bytree**: fracción de features usadas en cada árbol.\n",
    "\n",
    "XGBoost es mucho más pesado que los anteriores algoritmos, así que como sólo se necesita en este punto para selección de características se evaluará usando 5 iteraciones aleatorias del grid de parámetros.\n",
    "\n",
    "Se evaluan 5 combinaciones aleatorias de los hiperparámetros siguientes:\n",
    "* **n_estimators**: 200 a 1000\n",
    "* **max_depth**: 4 a 12\n",
    "* **learning_rate**: 0.05 a 0.3\n",
    "* **min_child_weight**: 1 a 5\n",
    "* **reg_alpha**: 0 a 1\n",
    "* **reg_lambda**: 1 a 10\n",
    "* **subsample**: 0.8 a 1.0\n",
    "* **colsample_bytree**: 0.8 a 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315209b-f9d5-4a30-bfe7-25e1726b8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Esta celda tarda alrededor de 6 minutos en el hardware original usado\n",
    "# Modelo XGBoost para selección de genes\n",
    "\n",
    "# Ratio de balanceo\n",
    "balance_value = (y_train==\"Non_response\").sum() / (y_train==\"Response\").sum()\n",
    "\n",
    "# Clases objetivo a binario: Non_response=0, Response=1\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "\n",
    "# Estimador\n",
    "xgboost = XGBClassifier(scale_pos_weight=balance_value, eval_metric=\"auc\", random_state=rng_seed)\n",
    "\n",
    "# Rangos de hiperparámetros\n",
    "xgboost_param_grid = {\n",
    "    \"n_estimators\": [\"I\", 200, 1000],\n",
    "    \"max_depth\": [\"I\", 4, 12],\n",
    "    \"learning_rate\": [\"F\", 0.05, 0.3],\n",
    "    \"min_child_weight\": [\"I\", 1, 5],\n",
    "    \"reg_alpha\": [\"I\", 0, 1],\n",
    "    \"reg_lambda\": [\"I\", 1, 10],\n",
    "    \"subsample\": [\"F\", 0.8, 1.0],\n",
    "    \"colsample_bytree\": [\"F\", 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Entrenamiento con validación cruzada\n",
    "xgboost_results = train_with_cv(\n",
    "    xgboost, xgboost_param_grid, X_train, y_train_encoded, scoring=\"roc_auc\", n_splits=5)\n",
    "\n",
    "print(\"Mejores parámetros: \", xgboost_results[\"best_params\"], \n",
    "      \"\\nMejor ROC_AUC=\", xgboost_results[\"best_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb5c47-f078-449c-9e8b-7805de755ee3",
   "metadata": {},
   "source": [
    "**Valores que se han obtenido**\n",
    "\n",
    "Checkpoint por si se vuelve a ejecutar y ya nos descuadra todo.\n",
    "Si eso sucediese, debería bastar con entrenar el modelo con los parámetros obtenido y que se muestran aquí abajo: \n",
    "\n",
    "**Mejores parámetros**:  {'n_estimators': 686, 'max_depth': 8, 'learning_rate': 0.13852815923040535, 'min_child_weight': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.9450004436079378, 'colsample_bytree': 0.8033351429612116} \n",
    "\n",
    "**Mejor ROC_AUC**= 0.737363661360528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6ce79a-61e2-4c58-a7b8-26d18ec6712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo de XGBoost\n",
    "best_xgboost_model = xgboost_results[\"best_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3c0e8-31c9-489b-b4b5-9739e37f7936",
   "metadata": {},
   "source": [
    "**CatBoost**\n",
    "\n",
    "* Algoritmo de boosting que maneja automáticamente variables categóricas.\n",
    "* Muy eficiente en datasets con alta cardinalidad y correlaciones.\n",
    "* Permite ponderar clases desbalanceadas con class_weights y pasándole una lista de pesos por clase.\n",
    "* Hiperparámetros clave:\n",
    "    * **iterations**: número de árboles.\n",
    "    * **depth**: profundidad máxima.\n",
    "    * **learning_rate**: tasa de aprendizaje.\n",
    "    * **l2_leaf_reg**: regularización L2 en hojas.\n",
    "    * **rsm**: Fracción de las características a usar en cada iteración de boosting.\n",
    "\n",
    "CatBoost, también es más pesado que los Regresión Logística y que Random Forest, así que como sólo se necesita en este punto para selección de características se evaluará usando 5 iteraciones aleatorias del grid de parámetros.\n",
    "\n",
    "Se evaluan 5 combinaciones aleatorias de los hiperparámetros siguientes:\n",
    "* **iterations**: 200 a 1000\n",
    "* **depth**: 4 a 8\n",
    "* **learning_rate**: 0.01 a 0.3\n",
    "* **l2_leaf_reg**: 1 a 5\n",
    "* **rsm**: 0.8 a 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f4485-43c1-4224-8352-494780b9276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Esta celda tarda alrededor de 10 minutos en el hardware original usado\n",
    "# Modelo CatBoost para selección de genes\n",
    "\n",
    "# Ratio de balanceo\n",
    "balance_value = (y_train==\"Non_response\").sum() / (y_train==\"Response\").sum()\n",
    "\n",
    "# Estimador\n",
    "catboost = CatBoostClassifier(class_weights=[1, balance_value], eval_metric=\"AUC\", \n",
    "                              early_stopping_rounds=50, random_state=rng_seed)\n",
    "\n",
    "# Rangos de hiperparámetros\n",
    "catboost_param_grid = {\n",
    "    \"iterations\": [\"I\", 200, 1000],\n",
    "    \"depth\": [\"I\", 4, 8],\n",
    "    \"learning_rate\": [\"F\", 0.01, 0.3],\n",
    "    \"l2_leaf_reg\": [\"I\", 1, 5],\n",
    "    \"rsm\": [\"F\", 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Entrenamiento con validación cruzada\n",
    "catboost_results = train_with_cv(\n",
    "    catboost, catboost_param_grid, X_train, y_train_encoded, scoring=\"roc_auc\", n_splits=5)\n",
    "\n",
    "print(\"Mejores parámetros: \", catboost_results[\"best_params\"], \n",
    "      \"\\nMejor ROC_AUC=\", catboost_results[\"best_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b192c280-8caf-4782-b023-a892fe9416d1",
   "metadata": {},
   "source": [
    "**Valores que se han obtenido**\n",
    "\n",
    "Checkpoint por si se vuelve a ejecutar y ya nos descuadra todo.\n",
    "Si eso sucediese, debería bastar con entrenar el modelo con los parámetros obtenido y que se muestran aquí abajo: \n",
    "\n",
    "**Mejores parámetros**: {'iterations': 625, 'depth': 7, 'learning_rate': 0.08243629472071373, 'l2_leaf_reg': 3, 'rsm': 0.9543900570724763}\n",
    "\n",
    "**Mejor ROC_AUC**= 0.738325023616774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200045f-5556-463b-9dda-e50282d02206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor modelo de CatBoost\n",
    "best_catboost_model = catboost_results[\"best_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2136faf-dd1d-4912-bd25-bd8340123ee1",
   "metadata": {},
   "source": [
    "Una vez tenemos los modelos entrenados tenemos que hacer los siguientes pasos:\n",
    "\n",
    "1. Obtener las importancias de cada modelo\n",
    "2. Normalizarlas (para poder compararlas)\n",
    "3. Combinar los rankings de cada modelo\n",
    "4. Seleccionar las mejores features según el ranking global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda6ad7-17e5-4301-88a8-0d7f88cdcd09",
   "metadata": {},
   "source": [
    "#### 1.1 Obtener importancias de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af311b37-27f8-476a-a90d-66e129907a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener importancias de features según cada modelo\n",
    "logreg_importances = np.abs(best_logreg_model.coef_[0])\n",
    "rf_importances = best_rf_model.feature_importances_\n",
    "xgb_importances = best_xgboost_model.feature_importances_\n",
    "cat_importances = best_catboost_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a2ca9-23ec-4165-96bd-2ca50adb4415",
   "metadata": {},
   "source": [
    "#### 1.2 Normalizar importancias de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134cc234-4c57-4a92-82ce-7fed4e7a7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar importancias de cada modelo\n",
    "scaler = MinMaxScaler()\n",
    "all_importances = np.vstack([\n",
    "    logreg_importances,\n",
    "    rf_importances,\n",
    "    xgb_importances,\n",
    "    cat_importances\n",
    "])\n",
    "normalized = scaler.fit_transform(all_importances.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df0f5c-7b85-4f49-8e09-53ffeee1adee",
   "metadata": {},
   "source": [
    "#### 1.3 Combinar rankings\n",
    "\n",
    "Se pueden usar diferentes métodos como promedio entre rankings, voto mayoritario o intersección.\n",
    "\n",
    "En este caso se opta por promedio entre rankings, debido a su sencillez, flexibilidad (no descarta características importantes detectadas por sólo un modelo) y suavidad que aporta (un modelo tiene más dificil dominar los demás por completo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822246a-4078-420b-87ce-b0d8afdae647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar rankings: Promedio de importancias\n",
    "feature_names = X_train_scaled.columns\n",
    "mean_importances = normalized.mean(axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"LogisticRegression\": normalized[0],\n",
    "    \"RandomForest\": normalized[1],\n",
    "    \"XGBoost\": normalized[2],\n",
    "    \"CatBoost\": normalized[3],\n",
    "    \"mean_importance\": mean_importances\n",
    "}).sort_values(\"mean_importance\", ascending=False)\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623874c4-e1bf-405d-83f4-e70c97a6b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de top n más/menos importantes según el ranking global\n",
    "# Seleccionamos top-n más importantes y top-n menos importantes\n",
    "n = 20\n",
    "mean_val = importance_df[\"mean_importance\"].mean()\n",
    "\n",
    "# Centrar en 0\n",
    "importance_df[\"centered\"] = importance_df[\"mean_importance\"] - mean_val\n",
    "\n",
    "# Seleccionar top/bottom n\n",
    "top_features = importance_df.nlargest(n, \"centered\")\n",
    "bottom_features = importance_df.nsmallest(n, \"centered\")\n",
    "plot_df = pd.concat([top_features, bottom_features]).sort_values(\"centered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43594d4f-0e17-4836-9772-73c01005812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "plt.figure(figsize=(6,6))\n",
    "colors = plot_df[\"centered\"].apply(lambda x: \"tab:blue\" if x > 0 else \"tab:red\")\n",
    "plt.barh(plot_df[\"feature\"], plot_df[\"centered\"], color=colors)\n",
    "plt.axvline(0, color=\"black\", linewidth=0.8)\n",
    "plt.xlabel(\"Importancia relativa (centrada en la media)\")\n",
    "plt.yticks(fontsize=8)\n",
    "plt.title(f\"Top {n} y Bottom {n} features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb644f6-0214-43a4-91bb-9ef79ff41a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "colors = plot_df[\"centered\"].apply(lambda x: \"tab:blue\" if x > 0 else \"tab:red\")\n",
    "plt.hlines(y=plot_df[\"feature\"], xmin=0, xmax=plot_df[\"centered\"], color=colors)\n",
    "plt.plot(plot_df[\"centered\"], plot_df[\"feature\"], \"o\", color=\"black\")\n",
    "plt.axvline(0, color=\"black\", linewidth=0.8)\n",
    "plt.xlabel(\"Importancia relativa (centrada)\")\n",
    "plt.title(\"Lollipop divergente de importancias\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d449de-1df2-407e-a08a-737942fef318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las top-N por importancia media\n",
    "top_n = 20\n",
    "top_features = importance_df.nlargest(top_n, \"mean_importance\")\n",
    "\n",
    "# Construimos matriz para el heatmap\n",
    "heatmap_data = top_features.set_index(\"feature\")[[\"LogisticRegression\", \"RandomForest\", \"XGBoost\", \"CatBoost\", \"mean_importance\"]]\n",
    "\n",
    "# Dibujamos heatmap\n",
    "plt.figure(figsize=(7, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"YlGnBu\",        # paleta de colores\n",
    "    annot=True,           # muestra valores numéricos\n",
    "    fmt=\".2f\",            # formato de los números\n",
    "    cbar_kws={\"label\": \"Importancia normalizada\"}\n",
    ")\n",
    "plt.title(f\"Heatmap de importancias (Top {top_n} features)\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.xticks(rotation=30, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2c3f6-9503-4587-b901-42d62c71dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las top-N por importancia media\n",
    "bottom_n = 20\n",
    "bottom_features = importance_df.nsmallest(bottom_n, \"mean_importance\")\n",
    "\n",
    "# Construimos matriz para el heatmap\n",
    "heatmap_data = bottom_features.set_index(\"feature\")[[\"LogisticRegression\", \"RandomForest\", \"XGBoost\", \"CatBoost\", \"mean_importance\"]]\n",
    "heatmap_data = heatmap_data.sort_values(\"mean_importance\", ascending=False)\n",
    "\n",
    "# Dibujamos heatmap\n",
    "plt.figure(figsize=(7, 8))\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    cmap=\"gist_heat\",        # paleta de colores\n",
    "    annot=True,           # muestra valores numéricos\n",
    "    fmt=\".2f\",            # formato de los números\n",
    "    cbar_kws={\"label\": \"Importancia normalizada\"}\n",
    ")\n",
    "plt.title(f\"Heatmap de importancias (Top {top_n} features)\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.xticks(rotation=30, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a689b0-f554-4183-a478-030a690450e8",
   "metadata": {},
   "source": [
    "#### 1.4 Seleccionar las mejores features según importancia global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd2ae8-b062-4621-9492-9f6d651c0e9f",
   "metadata": {},
   "source": [
    "Llegados a este punto hay que decidir dónde cortar. Se comentó durante la fase de exploración que como referencia, para priorizar la explicabilidad operativa, el objetivo para el dataset final sería tener alrededor de unas 20 características. Esa es la referencia, el número concreto lo decidiremos en base a criterio técnico.\n",
    "\n",
    "Se probarán los siguientes métodos para seleccionar las características finales:\n",
    "* **Usar detección de codo**: Ordenar las importancias de mayor a menor y detectar el codo.\n",
    "* **Clusterizar con k-means**: Crear clústers basados en 3 niveles de importancia (alta, media, baja) y seleccionar las características del clúster de mayor importancia media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c20d1-572d-4bab-bcc6-00b498b5c11c",
   "metadata": {},
   "source": [
    "**Detección de codo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0898904f-d470-499d-909a-28d63020ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar las importancias de mayor a menor\n",
    "importances_sorted = np.sort(importance_df[\"mean_importance\"].values)[::-1]\n",
    "\n",
    "# Índices de las features\n",
    "x = range(1, len(importances_sorted) + 1)\n",
    "\n",
    "# Detectar el \"codo\" con KneeLocator\n",
    "# La curva es convexa\n",
    "knee = KneeLocator(\n",
    "    x,\n",
    "    importances_sorted,\n",
    "    curve=\"convex\",\n",
    "    direction=\"decreasing\"\n",
    ")\n",
    "\n",
    "elbow_point = knee.knee\n",
    "\n",
    "# Dibujar el gráfico\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(x, importances_sorted, marker=\"o\")\n",
    "plt.axvline(elbow_point, color=\"red\", linestyle=\"--\", label=f\"Codo en {elbow_point}\")\n",
    "plt.xlabel(\"Features ordenadas por importancia\")\n",
    "plt.ylabel(\"Importancia media\")\n",
    "plt.title(\"Curva de importancias y punto de corte (codo)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"El punto de corte sugerido por KneeLocator es: {elbow_point} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606fe94d-a00c-43b4-8cc0-8e319c4e5a3f",
   "metadata": {},
   "source": [
    "El método del codo detecta un punto de corte extremadamente agresivo que selecciona sólo 7 características.\n",
    "\n",
    "Se espera que con el método k-means esa cifra sea más razonable y cercana a los 20 de referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c8f70-0fde-4455-b8b9-2f586bf95820",
   "metadata": {},
   "source": [
    "**Elección de clúster con mayor importancia media K-means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c885e5f-d4a6-41fd-9e99-52af26c9af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos las importancias como array\n",
    "X = importance_df[[\"mean_importance\"]].values\n",
    "\n",
    "# Definir número de clusters (alto, medio, bajo)\n",
    "kmeans = KMeans(n_clusters=3, random_state=rng_seed)\n",
    "importance_df[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# Ordenar los clusters por la media de importancia (para que 0 = bajo, 2 = alto)\n",
    "cluster_order = importance_df.groupby(\"cluster\")[\"mean_importance\"].mean().sort_values().index\n",
    "mapping = {old:new for new, old in enumerate(cluster_order)}\n",
    "importance_df[\"cluster\"] = importance_df[\"cluster\"].map(mapping)\n",
    "\n",
    "# Dibujar gráfico\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(len(importance_df)), importance_df[\"mean_importance\"], \n",
    "            c=importance_df[\"cluster\"], cmap=\"viridis\", s=50)\n",
    "plt.xlabel(\"Features (ordenadas)\")\n",
    "plt.ylabel(\"Importancia media\")\n",
    "plt.title(\"Clusterización de importancias (KMeans)\")\n",
    "plt.colorbar(label=\"Clúster (0=bajo, 1=medio, 2=alto)\")\n",
    "plt.show()\n",
    "\n",
    "# Seleccionar las características del clúster con más importancia media\n",
    "selected_features = importance_df[importance_df[\"cluster\"] == 2][\"feature\"].tolist()\n",
    "print(f\"{len(selected_features)} features seleccionadas:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93296a7-848b-4b5a-a4fd-8ec8ec490bc3",
   "metadata": {},
   "source": [
    "El número de características está algo por encima de la cifra que usamos como referencia, pero preferimos ceñirnos al criterio técnico y usar esas características que parecen acumular la mayor área de importancia según la clusterización realizada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36e49c-18f1-422a-97a7-2a70c37ab583",
   "metadata": {},
   "source": [
    "#### 1.5 Creación de los datasets finales con las características selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13043394-faf7-418d-89c8-a65762798b2e",
   "metadata": {},
   "source": [
    "Por si en otro momento se quieren probar otros análisis, con los datasets con las características seleccionadas se crearán versiones finales del dataset completo original, todos los subconjuntos usados y todos los subconjuntos escalados.\n",
    "\n",
    "**NOTA**: Esto también valdrá en caso de que por cualquier problema de aleatorización el presente notebook deje de tener datos coherentes con el estudio. Estos ficheros creados aquí deberán valer para continuar el estudio a partir de este punto como copia de seguridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f4787-591e-44be-86ac-a68211311b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas finales\n",
    "final_columns = selected_features + [\"Sample_id\", \"Response\"]\n",
    "\n",
    "# Crear versiones finales de cada dataset\n",
    "df_full_final = df_full[final_columns].copy()\n",
    "\n",
    "df_train_final = df_train[final_columns].copy()\n",
    "df_test_final = df_test[final_columns].copy()\n",
    "df_cal_final = df_cal[final_columns].copy()\n",
    "\n",
    "df_scaled_train_final = df_scaled_train[final_columns].copy()\n",
    "df_scaled_test_final = df_scaled_test[final_columns].copy()\n",
    "df_scaled_cal_final = df_scaled_cal[final_columns].copy()\n",
    "\n",
    "# Mostrar ejemplo de dataset final\n",
    "print(\"Train final shape:\", df_train_final.shape)\n",
    "print(\"Test final shape:\", df_test_final.shape)\n",
    "df_train_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7cf0a7-775b-4460-ae02-7937da277e26",
   "metadata": {},
   "source": [
    "Para rematar los datasets finales y guardarlos, primero conviene hacer alguna comprobación de integridad, estar seguros de que no se ha cometido algún error a la hora de manipular columnas, fusionar datos, etc.\n",
    "\n",
    "La siguiente función comprueba si para el dataset original y el dataset final, la misma combinación de gen y sample_id siguen teniendo el mismo valor en ambos casos. Esa prueba se repite 'n' veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452d7a6-5476-4e0e-94ca-b8c3f3339765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_df_consistency(df_original, df_final, n=100):\n",
    "    \"\"\"\n",
    "    Comprueba aleatoriamente si los valores coinciden entre df_original y df_final\n",
    "    para las mismas combinaciones de Sample_id y columna (gen).\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    df_original : pandas dataframe\n",
    "        DataFrame completo\n",
    "    df_final : pandas dataframe\n",
    "        DataFrame reducido (con Sample_id, Response y features seleccionadas)\n",
    "    n : int\n",
    "        número de comprobaciones aleatorias\n",
    "    \n",
    "    Imprime\n",
    "    -------\n",
    "    Los primeros 5 resultados de la comprobación\n",
    "    \n",
    "    Un mensaje final de éxito o fracaso\n",
    "    \"\"\"\n",
    "    \n",
    "    # Columnas que están en el dataset final (excluyendo Sample_id y Response)\n",
    "    columnas_finales = [c for c in df_final.columns if c not in [\"Sample_id\", \"Response\"]]\n",
    "    \n",
    "    # Sample_ids presentes en df_final\n",
    "    sample_ids = df_final[\"Sample_id\"].unique()\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # Elegir aleatoriamente un sample_id y una columna\n",
    "        sample_id = rng.choice(sample_ids)\n",
    "        col = rng.choice(columnas_finales)\n",
    "        \n",
    "        # Obtener valores\n",
    "        orig_value = df_original.loc[df_original[\"Sample_id\"] == sample_id, col].iloc[0]\n",
    "        final_value = df_final.loc[df_final[\"Sample_id\"] == sample_id, col].iloc[0]\n",
    "        \n",
    "        is_match = (orig_value == final_value)\n",
    "        \n",
    "        resultados.append(\n",
    "            (str(sample_id), str(col), float(orig_value), float(final_value), bool(is_match)))\n",
    "    \n",
    "    # Mostrar solo los primeros 5\n",
    "    print(\"Primeras 5 comprobaciones:\")\n",
    "    for r in resultados[:5]:\n",
    "        print(r)\n",
    "    \n",
    "    # Mostrar mensaje final\n",
    "    if all(r[-1] for r in resultados):\n",
    "        print(\"\\nVerificación completada: todos los valores coinciden.\\n-------\\n\")\n",
    "    else:\n",
    "        print(\"\\nWARNING!! Inconsistencias detectadas: algunos valores no coinciden.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016c48c-a6fa-49e8-b129-0bed03ffe3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobación de 1000 datos aleatorios entre datasets iniciales y finales\n",
    "check_df_consistency(df_full, df_full_final, n=1000)\n",
    "check_df_consistency(df_train, df_train_final, n=1000)\n",
    "check_df_consistency(df_test, df_test_final, n=1000)\n",
    "check_df_consistency(df_cal, df_cal_final, n=1000)\n",
    "check_df_consistency(df_scaled_train, df_scaled_train_final, n=1000)\n",
    "check_df_consistency(df_scaled_test, df_scaled_test_final, n=1000)\n",
    "check_df_consistency(df_scaled_cal, df_scaled_cal_final, n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b91e9-051c-4fc4-a20b-717768320f1d",
   "metadata": {},
   "source": [
    "Llegados a este punto ya se pueden guardar los datasets finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cec7d-ed1b-49af-8589-6c54a2280e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los datasets\n",
    "df_full_final.to_csv(\"./data/final/full_top_significance_reduced_feat.csv\", index=False)\n",
    "df_train_final.to_csv(\"./data/final/train_reduced_feat.csv\", index=False)\n",
    "df_test_final.to_csv(\"./data/final/test_reduced_feat.csv\", index=False)\n",
    "df_cal_final.to_csv(\"./data/final/cal_reduced_feat.csv\", index=False)\n",
    "df_scaled_train_final.to_csv(\"./data/final/scaled_train_reduced_feat.csv\", index=False)\n",
    "df_scaled_test_final.to_csv(\"./data/final/scaled_test_reduced_feat.csv\", index=False)\n",
    "df_scaled_cal_final.to_csv(\"./data/final/scaled_cal_reduced_feat.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
